# MultiMedia-LLM-Summarization-Tool

Welcome to the **LLM Summarizer**! This application utilizes multiple cutting-edge Language Model (LLMs) capabilities to generate concise and insightful summaries from diverse input formats. Whether you have a video, a PDF document, or an audio file, this tool can help distill key points efficiently.

---

## ğŸš€ Features

### ğŸ“º Summarize YouTube Videos
- Upload a custom .mp4 video to generate a text-based summary of its audio content (leveraging automated transcription).

### ğŸ“„ Summarize PDFs
- Upload a PDF document, and the tool will parse its text to create a concise summary.

### ğŸ§ Summarize Audio Files
- Upload an audio file, and the tool will convert its content to text using speech-to-text technology and generate a summary.

### âœ‚ï¸ Character Limit Control
- Summaries are tailored to fit your desired length, ensuring they remain concise and relevant.

### ğŸ¤– Multiple LLM Selection
- Choose from various AI models for summarization, including **GPT-4o-mini**, **qwen 2.5**, **llama3.2**, **gemma** and **mistral**, to match your specific needs.

### ğŸŒˆ Seamless User Experience
- Built using **Streamlit**, the web interface is simple, responsive, and user-friendly.

---

## ğŸ› ï¸ How It Works

1. **Input Formats:**
   - .mp4 Video File
   - PDF File
   - .mp3 / .wav Audio File

2. **Processing:**
   - Extracts relevant content from the input.
   - Uses an LLM (e.g., OpenAI's GPT-4o-mini) to analyze and summarize the content.

3. **Output:**
   - Displays the summary directly on the web page.

---

## ğŸ§‘â€ğŸ’» Technologies Used

- **Backend:** LLM Models ->  GPT-4o-mini, Qwen 2.5, Gemma, Llama3.3, Mistral
- **Frontend:** Streamlit for a dynamic web interface.
- **Additional Tools:**
  - `PyPDF2` for PDF parsing.
  - `Whisper` for speech-to-text tools and audio/video file processing.

---

## ğŸ–¥ï¸ Installation and Usage

### Prerequisites
- Python 3.11+
- An OpenAI API Key.
- Ollama's Open source Models.
- Ensure you have ffmpeg installed and added to PATH, for Speech-to-Text conversion.

### Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/brickster241/LLM_Projects.git
   ```

2. Go inside directory, create and activate environment and install required dependencies using Anaconda:
   ```bash
   cd MultiMedia-LLM-Summarization-Tool
   conda create --name llm_env python=3.11
   conda activate llm_env
   pip install -r requirements.txt
   ```

3. Add a `.env` file, containing `OPEN_API_KEY=yourAPIKey`.

4. In case you want to use LLMs other than `gpt-4o-mini`, install Ollama and download models : 
   ```bash
   ollama run gemma:7b
   ollama run qwen2.5:7b
   ollama run llama3.2:3b
   ollama run mistral:7b
   ```

### Usage

1. Navigate to the LLM-Summarizer directory and Run the Streamlit app:
   ```bash
   cd LLM_Summarizer
   streamlit run app.py
   ```

2. Open your browser and navigate to the local URL provided by Streamlit (e.g., `http://localhost:8501`).

3. Upload video, upload a PDF file, or upload an audio file to get your summary!

---

## ğŸ“¦ File Structure

```plaintext
LLM-Projects/
â”œâ”€â”€ .env                         # .env File for storing OPENAI API Key
â”œâ”€â”€ LLM-Summarizer/              # Project Directory
â”‚   â”œâ”€â”€ llm_summarizer.py        # PDF file, Audio file, Youtube URL processing logic
â”‚   â”œâ”€â”€ streamlit_app.py         # Main Streamlit App
â”‚   â”œâ”€â”€ README.md                # Project documentation
â”‚   â”œâ”€â”€ requirements.txt         # Requirements.txt file for creating environment
```

---
